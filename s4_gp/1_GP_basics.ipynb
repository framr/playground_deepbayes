{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian Processes (GP) with GPy\n",
    "\n",
    "We will use GPy library for GP modeling [SheffieldML github page](https://github.com/SheffieldML/GPy).\n",
    "\n",
    "Why **GPy**?\n",
    "\n",
    "* Specialized library of GP models (regression, classification, GPLVM)\n",
    "* Variety of covariance functions is implemented\n",
    "* There are GP models for large-scale problems\n",
    "* Easy to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Uncomment and run the following line to install GPy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pip install GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Current documentation of GPy library can be found [here](http://gpy.readthedocs.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian Process Regression\n",
    "\n",
    "A data set $\\left (X, \\mathbf{y} \\right ) = \\left \\{ (x_i, y_i), x_i \\in \\mathbb{R}^d, y_i \\in \\mathbb{R} \\right \\}_{i = 1}^N$ is given.  \n",
    "\n",
    "Assumption:\n",
    "$$\n",
    "y = f(x) + \\varepsilon,\n",
    "$$\n",
    "where $f(x)$ is a Gaussian Processes and $\\varepsilon \\sim \\mathcal{N}(0, \\sigma_n^2)$ is a Gaussian noise ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Posterior distribution\n",
    "$$\n",
    "y_* | X, \\mathbf{y}, x_* \\sim \\mathcal{N}(m(x_*), \\sigma(x_*)),\n",
    "$$\n",
    "with predictive mean and variance given by\n",
    "$$\n",
    "m(x_*) = \\mathbf{k}^T \\mathbf{K}_y^{-1} \\mathbf{y} = \\sum_{i = 1}^N \\alpha_i k(x_*, x_i),\n",
    "$$\n",
    "$$\n",
    "\\sigma^2(x_*) = k(x_*, x_*) - \\mathbf{k}^T\\mathbf{K}_y^{-1}\\mathbf{k},\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mathbf{k} = \\left ( k(x_*, x_1), \\ldots, k(x_*, x_N) \\right )^T\n",
    "$$\n",
    "$$\n",
    "\\mathbf{K}_y = \\|k(x_i, x_j)\\|_{i, j = 1}^N + \\sigma_n^2 \\mathbf{I}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building GPR model\n",
    "\n",
    "Lets fit GPR model for function $f(x) = âˆ’ \\cos(\\pi x) + \\sin(4\\pi x)$ in $[0, 1]$,\n",
    "with noise $y(x) = f(x) + \\epsilon$, $\\epsilon \\sim \\mathcal{N}(0, 0.1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "X = np.linspace(0.05, 0.95, N).reshape(-1, 1)\n",
    "Y = -np.cos(np.pi * X) + np.sin(4 * np.pi * X) + \\\n",
    "    np.random.normal(loc=0.0, scale=0.1, size=(N, 1))\n",
    "pyplot.figure(figsize=(5, 3))\n",
    "pyplot.plot(X, Y, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1. Define covariance function\n",
    "\n",
    "The most popular kernel - RBF kernel - has 2 parameters: `variance` and `lengthscale`, $k(x, y) = \\sigma^2 \\exp\\left ( -\\dfrac{\\|x - y\\|^2}{2l^2}\\right )$,\n",
    "where `variance` is $\\sigma^2$, and `lengthscale` - $l$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 1\n",
    "variance = 1\n",
    "lengthscale = 0.2\n",
    "kernel = GPy.kern.RBF(input_dim, variance=variance,\n",
    "                      lengthscale=lengthscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2. Create GPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = GPy.models.GPRegression(X, Y, kernel)\n",
    "print(model)\n",
    "model.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameters of the covariance function\n",
    "\n",
    "Values of parameters of covariance function can be set like:  `k.lengthscale = 0.1`.\n",
    "\n",
    "Let's change the value of `lengthscale` parameter and see how it changes the covariance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = GPy.kern.RBF(1)\n",
    "theta = np.asarray([0.2, 0.5, 1, 2, 4, 10])\n",
    "figure, axes = pyplot.subplots(2, 3, figsize=(8, 4))\n",
    "for t, ax in zip(theta, axes.ravel()):\n",
    "    k.lengthscale = t\n",
    "    k.plot(ax=ax)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_xlim([-4, 4])\n",
    "    ax.legend([t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task\n",
    "Try to change parameters to obtain more accurate mdoel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "######## Your code here ########\n",
    "kernel = GPy.kern.RBF(1, lengthscale=)\n",
    "model = \n",
    "\n",
    "print(model)\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tuning parameters of covariance function\n",
    "\n",
    "The parameters are tuned by maximizing likelihood. To do it just use `optimize()` method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.optimize()\n",
    "print(model)\n",
    "model.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: `optimize()` maximizes likelihood.  However, for GP there is an expression for LOO predictive mean and variance\n",
    "$$\n",
    "\\mu_i = y_i - \\frac{ \\left [ \\mathbf{K}^{-1}\\mathbf{y} \\right ]_i }{\\left [ \\mathbf{K}^{-1} \\right ]_{ii}},\n",
    "$$\n",
    "$$\n",
    "\\sigma_i = \\frac{1}{\\mathbf{K}^{-1}_{ii}}\n",
    "$$\n",
    "Then, e.g. MSE-LOO\n",
    "$$\n",
    "{\\rm MSE-LOO} = \\frac{1}{N}\\sum_{i = 1}^N \\left (\\frac{\\mathbf{K}^{-1}\\mathbf{y}}{\\mathbf{K}^{-1}_{ii}} \\right )^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Noise variance\n",
    "\n",
    "Noise variance acts like a regularization in GP models. Larger values of noise variance lead to more smooth model.  \n",
    "Let's check it: try to change noise variance to some large value, to some small value and see the results.\n",
    "\n",
    "Noise variance accessed like this: `model.Gaussian_noise.variance = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "######## Your code here ########\n",
    "model.Gaussian_noise.variance = \n",
    "model.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's generate more noisy data and try to fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N = 40\n",
    "X = np.linspace(0.05, 0.95, N).reshape(-1, 1)\n",
    "Y = -np.cos(np.pi * X) + np.sin(4 * np.pi * X) + \\\n",
    "    np.random.normal(loc=0.0, scale=0.5, size=(N, 1))\n",
    "\n",
    "kernel = GPy.kern.RBF(1)\n",
    "model = GPy.models.GPRegression(X, Y, kernel)\n",
    "model.optimize()\n",
    "print(model)\n",
    "model.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, let's fix noise variance to some small value and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(1)\n",
    "model = GPy.models.GPRegression(X, Y, kernel)\n",
    "model.Gaussian_noise.variance.fix(0.01)\n",
    "model.optimize()\n",
    "model.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian Process Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification\n",
    "\n",
    "A data set $\\left (X, \\mathbf{y} \\right ) = \\left \\{ (x_i, y_i), x_i \\in \\mathbb{R}^d, y_i \\in \\{+1, -1\\} \\right \\}_{i = 1}^N$ is given.  \n",
    "\n",
    "Assumption:\n",
    "$$\n",
    "p(y = +1 \\; | \\; x) = \\sigma(f(x)) = \\pi(x),\n",
    "$$\n",
    "where latent function $f(x)$ is a Gaussian Processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to produce a probabilistic prediction\n",
    "$$\n",
    "\\pi_* = p(y_* \\; | \\; X, \\mathbf{y}, x_*) = \\int \\sigma(f_*) p(f_* \\; | \\; X, \\mathbf{y}, x_*) df_*,\n",
    "$$\n",
    "$$\n",
    "p(f_* \\; | \\; X, \\mathbf{y}, x_*) = \\int p(f_* \\; | \\; X, x_*, \\mathbf{f}) p(\\mathbf{f} \\; | \\; X, \\mathbf{y}) d\\mathbf{f},\n",
    "$$\n",
    "where $p(\\mathbf{f} \\; |\\; X, \\mathbf{y}) = \\dfrac{p(\\mathbf{y} | X, \\mathbf{f}) p(\\mathbf{f} | X)}{p(\\mathbf{y} | X)}$ is the posterior over the latent variables.\n",
    "\n",
    "Both integrals are intractable.\n",
    "\n",
    "Use approximation technique like Laplace approximation or Expectation Propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "def cylinder(x):\n",
    "    y = (1 / 7.0 - (x[:, 0] - 0.5)**2 - (x[:, 1] - 0.5)**2) > 0\n",
    "    return y\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(40, 2)\n",
    "y = cylinder(X)\n",
    "\n",
    "x_grid = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "y_grid = cylinder(np.hstack((x_grid[0].reshape(-1, 1), x_grid[1].reshape(-1, 1)))).reshape(x_grid[0].shape)\n",
    "\n",
    "positive_idx = y == 1\n",
    "pyplot.figure(figsize=(5, 3))\n",
    "pyplot.plot(X[positive_idx, 0], X[positive_idx, 1], '.', markersize=10, label='Positive')\n",
    "pyplot.plot(X[~positive_idx, 0], X[~positive_idx, 1], '.', markersize=10, label='Negative')\n",
    "im = pyplot.contour(x_grid[0], x_grid[1], y_grid, 10, cmap=cm.hot)\n",
    "pyplot.colorbar(im)\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(2, variance=1., lengthscale=0.2, ARD=True)\n",
    "\n",
    "model = GPy.models.GPClassification(X, y.reshape(-1, 1), kernel=kernel)\n",
    "model.optimize()\n",
    "print(model)\n",
    "\n",
    "\n",
    "def plot_model_2d(model):\n",
    "\n",
    "    model.plot(levels=40, resolution=80, plot_data=False, figsize=(5, 3))\n",
    "    pyplot.plot(X[positive_idx, 0], X[positive_idx, 1], '.', markersize=10, label='Positive')\n",
    "    pyplot.plot(X[~positive_idx, 0], X[~positive_idx, 1], '.', markersize=10, label='Negative')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "    \n",
    "plot_model_2d(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's change lengthscale to some small value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.rbf.lengthscale = [0.05, 0.05]\n",
    "plot_model_2d(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Covariance functions\n",
    "\n",
    "Short info about covariance function can be printed using `print(k)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k = GPy.kern.RBF(1)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can plot the covariance function using `plot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heaviside function\n",
    "\n",
    "The most popular covariance function is RBF. However, not all the functions can be modelled using RBF covariance function. For example, approximations of functions with large gradients or discontinuities will suffer from oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def heaviside(x):\n",
    "    return np.asfarray(x > 0)\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "y = heaviside(x)\n",
    "pyplot.figure(figsize=(5, 3))\n",
    "pyplot.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(30, 1) * 2 - 1\n",
    "y = heaviside(X)\n",
    "\n",
    "k = GPy.kern.RBF(input_dim=1, variance=1., lengthscale=1.)\n",
    "\n",
    "m = GPy.models.GPRegression(X, y, k)\n",
    "m.optimize()\n",
    "print(m)\n",
    "m.plot(figsize=(5, 3))\n",
    "pyplot.ylim([-0.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Covariance functions in GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Popular covariance functions: `Exponential`, `Matern32`, `Matern52`, `RatQuad`, `Linear`, `StdPeriodic`. \n",
    "\n",
    "* Exponential:\n",
    "$$\n",
    "k(x, x') = \\sigma^2 \\exp \\left (-\\frac{r}{l} \\right), \\quad r = \\|x - x'\\|\n",
    "$$\n",
    "\n",
    "* Matern32\n",
    "$$\n",
    "k(x, x') = \\sigma^2 \\left (1 + \\sqrt{3}\\frac{r}{l} \\right )\\exp \\left (-\\sqrt{3}\\frac{r}{l} \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Matern52\n",
    "$$\n",
    "k(x, x') = \\sigma^2 \\left (1 + \\sqrt{5}\\frac{r}{l} + \\frac{5}{3}\\frac{r^2}{l^2} \\right ) \\exp \\left (-\\sqrt{5}\\frac{r}{l} \\right )\n",
    "$$\n",
    "\n",
    "* RatQuad\n",
    "$$\n",
    "k(x, x') = \\left ( 1 + \\frac{r^2}{2\\alpha l^2}\\right )^{-\\alpha}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Linear\n",
    "$$\n",
    "k(x, x') = \\sum_i \\sigma_i^2 x_i x_i'\n",
    "$$\n",
    "\n",
    "* Poly\n",
    "$$\n",
    "k(x, x') = \\sigma^2 (x^T x' + c)^d\n",
    "$$\n",
    "\n",
    "* StdPeriodic\n",
    "$$\n",
    "k(x, x') = \\sigma^2 \\exp\\left ( -2 \\frac{\\sin^2(\\pi r)}{l^2}\\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "covariance_functions = [GPy.kern.Exponential(1), GPy.kern.Matern32(1),\n",
    "                        GPy.kern.RatQuad(1), GPy.kern.Linear(1),\n",
    "                        GPy.kern.Poly(1), GPy.kern.StdPeriodic(1)]\n",
    "figure, axes = pyplot.subplots(2, 3, figsize=(9, 6))\n",
    "axes = axes.ravel()\n",
    "for i, k in enumerate(covariance_functions):\n",
    "    k.plot(ax=axes[i])\n",
    "    axes[i].set_title(k.name)\n",
    "figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What covariance function we should use to obatin more accurate approximation of Heaviside function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combination of covariance functions\n",
    "\n",
    "* Sum of covariance function is a valid covariance function:\n",
    "\n",
    "$$\n",
    "k(x, x') = k_1(x, x') + k_2(x, x')\n",
    "$$\n",
    "\n",
    "* Product of covariance functions is a valid covariance funciton:\n",
    "$$\n",
    "k(x, x') = k_1(x, x') k_2(x, x')\n",
    "$$\n",
    "\n",
    "### Combinations of covariance functions in GPy\n",
    "\n",
    "In GPy to combine covariance functions you can just use operators `+` and `*`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, to define covariance function that is a sum of covariance functions we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kern1 = GPy.kern.Linear(1)\n",
    "kern2 = GPy.kern.RBF(1, variance=2., lengthscale=1)\n",
    "kern = kern1 + kern2\n",
    "print(kern)\n",
    "kern.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Linear times Periodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kern = GPy.kern.Linear(1) * GPy.kern.StdPeriodic(1)\n",
    "print(kern)\n",
    "kern.plot(figsize=(5, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Additive kernels\n",
    "\n",
    "One of the popular approach to model the function of interest is\n",
    "$$\n",
    "f(x) = \\sum_{i=1}^d f_i(x_i) + \\sum_{i < j} f_{ij}(x_i, x_j) + \\ldots\n",
    "$$\n",
    "\n",
    "**Example**: $\\quad f(x_1, x_2) = f_1(x_1) + f_2(x_2)$  \n",
    "To model it using GP use additive kernel $\\quad k(x, y) = k_1(x_1, y_1) + k_2(x_2, y_2)$.\n",
    "\n",
    "More general - add kernels each depending on subset of inputs\n",
    "$$\n",
    "k(x, y) = k_1(x, y) + \\ldots + k_D(x, y),\n",
    "$$\n",
    "where, for example, $k_1(x, x') = k_1(x_1, x_1'), \\; k_2(x, x') = k_2((x_1, x_3), (x_1', x_3'))$, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k1 = GPy.kern.RBF(1, active_dims=[0])\n",
    "k2 = GPy.kern.RBF(1, active_dims=[1])\n",
    "\n",
    "kernel = k1 + k2\n",
    "\n",
    "x = np.meshgrid(np.linspace(-3, 3, 50), np.linspace(-3, 3, 50))\n",
    "x = np.hstack((x[0].reshape(-1, 1), x[1].reshape(-1, 1)))\n",
    "z = kernel.K(x, np.array([[0, 0]]))\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "figure = pyplot.figure()\n",
    "ax = figure.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(x[:, 0].reshape(50, 50), x[:, 1].reshape(50, 50), z.reshape(50, 50), cmap=cm.jet)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Kernels on arbitrary types of objects\n",
    "\n",
    "Kernels can be defined over all types of data structures: text, images, matrices, graphs, etc. You just need to define similarity between objects.\n",
    "\n",
    "#### Kernels on categorical data\n",
    "\n",
    "* Represent your categorical variable as a by a one-of-k encoding: $\\quad x = (x_1, \\ldots, x_k)$.\n",
    "* Use RBF kernel with `ARD=True`: $\\quad k(x , x') = \\sigma^2 \\prod_{i = 1}^k\\exp{\\left ( -\\dfrac{(x_i - x_i')^2}{\\sigma_i^2} \\right )}$. The lengthscale will now encode whether the rest of the function changes.\n",
    "* Short lengthscales for categorical variables means your model is not sharing any information between data of different categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 Sampling from GP\n",
    "\n",
    "GP defines distribution over functions, which is defined by its *mean function* $m(x)$ and *covariance function* $k(x, y)$: for any set $\\mathbf{x}_1, \\ldots, \\mathbf{x}_N \\in \\mathbb{R}^d \\rightarrow$ $\\left (f(\\mathbf{x}_1), \\ldots, f(\\mathbf{x}_N) \\right ) \\sim \\mathcal{N}(\\mathbf{m}, \\mathbf{K})$,\n",
    "where $\\mathcal{m} = (m(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N)$, $\\mathbf{K} = \\|k(\\mathbf{x}_i, \\mathbf{x}_j)\\|_{i,j=1}^N$.\n",
    "\n",
    "Sampling procedure:\n",
    "\n",
    "1. Generate set of points $\\mathbf{x}_1, \\ldots, \\mathbf{x}_N$.\n",
    "2. Calculate mean and covariance matrix $\\mathcal{m} = (m(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N)$, $\\mathbf{K} = \\|k(\\mathbf{x}_i, \\mathbf{x}_j)\\|_{i,j=1}^N$.\n",
    "3. Generate vector from multivariate normal distribution $\\mathcal{N}(\\mathbf{m}, \\mathbf{K})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "\n",
    "Implement sampling from GP. Draw several samples from different kernels (RBF, Matern32, Matern52, Exponential, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "k = GPy.kern.RBF(input_dim=1, lengthscale=0.3)\n",
    "X = np.linspace(0, 5, 500).reshape(-1, 1)\n",
    "\n",
    "######## Your code here ########\n",
    "mu = <mean vector (zeros)>\n",
    "C = <covariance between points X>\n",
    "\n",
    "Z = <multivariate normal with mean mu and covariance matrix C>\n",
    "\n",
    "pyplot.figure()\n",
    "for i in range(3):\n",
    "    pyplot.plot(X, Z[i, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Task\n",
    "\n",
    "Build a GP model that predicts airline passenger counts on international flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat('airline.mat')\n",
    "\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "pyplot.figure(figsize=(5, 3))\n",
    "pyplot.plot(X, y, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to obtain something like this\n",
    "<img src=\"airline_result.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_model(X, y, kernel):\n",
    "    model = GPy.models.GPRegression(X, y, kernel)\n",
    "    model.optimize()\n",
    "    print(model)\n",
    "    \n",
    "    x = np.linspace(1948, 1964, 400).reshape(-1, 1)\n",
    "    prediction_mean, prediction_var = model.predict(x)\n",
    "    prediction_std = np.sqrt(prediction_var).ravel()\n",
    "    prediction_mean = prediction_mean.ravel()\n",
    "    \n",
    "    pyplot.figure(figsize=(5, 3))\n",
    "    pyplot.plot(X, y, '.', label='Train data')\n",
    "    pyplot.plot(x, prediction_mean, label='Prediction')\n",
    "    pyplot.fill_between(x.ravel(), prediction_mean - prediction_std, prediction_mean + prediction_std, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let's try RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k_rbf = GPy.kern.RBF(1)\n",
    "plot_model(X, y, k_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will try to model this data set using 3 additive components: trend, seasonality and noise.  \n",
    "So, the kernel should be a sum of 3 kernels:  \n",
    "`kernel = kernel_trend + kernel_seasonality + kernel_noise`\n",
    "\n",
    "#### Let's first try to model trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k_trend = \n",
    "plot_model(X, y, k_trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let's model periodicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k_trend = \n",
    "k_seasonal = \n",
    "kernel = k_trend + k_seasonal\n",
    "plot_model(X, y, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let's add noise model\n",
    "\n",
    "Tip: to model noise you can use `GPy.kern.White()` kernel which models noise at training points: $k_{white}(x, x') = \\delta(x - x')$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "k_trend = \n",
    "k_periodicity = \n",
    "k_noise = \n",
    "kernel = k_trend + k_periodicity + k_noise\n",
    "\n",
    "plot_model(X, y, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
